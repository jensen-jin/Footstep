#!/usr/bin/env python
"""
é€šç”¨æ¨¡å‹æ’­æ”¾è„šæœ¬ï¼Œè§£å†³è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
"""

import os
import sys

# å¼ºåˆ¶ä½¿ç”¨CPUï¼ˆå¦‚æœéœ€è¦ï¼‰
# os.environ['CUDA_VISIBLE_DEVICES'] = ''

import isaacgym
from gym.envs import *
from gym.utils import task_registry
import argparse
import torch

def play_model(experiment_name, checkpoint, num_envs=1, device='cpu'):
    """æ’­æ”¾è®­ç»ƒå¥½çš„æ¨¡å‹"""
    
    print(f"ğŸ® Playing model from experiment: {experiment_name}")
    print(f"ğŸ“‹ Checkpoint: {checkpoint}")
    print(f"ğŸ–¥ï¸  Device: {device}")
    print(f"ğŸ”¢ Environments: {num_envs}")
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    class Args:
        def __init__(self):
            self.task = 'humanoid_controller'
            self.experiment_name = experiment_name
            self.checkpoint = checkpoint
            self.num_envs = num_envs
            self.sim_device = device
            self.rl_device = device
            self.headless = False
            self.resume = False
            self.load_run = -1
            self.load_files = False
            self.run_name = None
            self.seed = None
            self.max_iterations = None
            self.wandb_project = None
            self.wandb_entity = None
            self.wandb_sweep_id = None
            self.wandb_sweep_config = None
            self.disable_wandb = True
            self.disable_local_saving = True
            self.sampling_method = None
            self.record = False
            
    args = Args()
    
    try:
        # åŠ è½½ç¯å¢ƒé…ç½®
        env, env_cfg = task_registry.make_env(name=args.task, args=args)
        print("âœ… Environment created successfully")
        
        # åŠ è½½è®­ç»ƒé…ç½®å’Œç­–ç•¥
        policy_runner, train_cfg = task_registry.make_alg_runner(env=env, name=args.task, args=args)
        print("âœ… Policy loaded successfully")
        
        # è¿è¡Œæ’­æ”¾
        print("ğŸš€ Starting playback...")
        env.reset()
        
        # æ’­æ”¾å¾ªç¯
        for i in range(1000):  # æ’­æ”¾1000æ­¥
            with torch.no_grad():
                obs = env.get_observations()
                actions = policy_runner.alg.actor(obs)
                env.step(actions)
                
            if i % 100 == 0:
                print(f"Step {i}/1000")
                
        print("âœ… Playback completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error during playback: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Play trained humanoid model")
    parser.add_argument("--experiment", type=str, required=True, help="Experiment name")
    parser.add_argument("--checkpoint", type=int, required=True, help="Checkpoint number")
    parser.add_argument("--num_envs", type=int, default=1, help="Number of environments")
    parser.add_argument("--device", type=str, default='cpu', choices=['cpu', 'cuda:0'], 
                       help="Device to use for simulation")
    
    args = parser.parse_args()
    
    success = play_model(args.experiment, args.checkpoint, args.num_envs, args.device)
    
    if success:
        print("ğŸ‰ Model playback successful!")
    else:
        print("ğŸ’¥ Model playback failed!")
        sys.exit(1)